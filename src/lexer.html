<html><head>
        <!-- Generated by Ddoc from /home/per/Work/justd/phobos-next/src/std/experimental/lexer.d -->
        <META http-equiv="content-type" content="text/html; charset=utf-8">
        <title>std.experimental.lexer</title>
        </head><body>
        <h1>std.experimental.lexer</h1>

 This module contains a range-based compile-time lexer generator.
<br><br>

 The lexer generator consists of a template mixin, , along with
 several helper templates for generating such things as token identifiers.
<br><br>

 To write a lexer using this API:
 <ol>     <li>Create the string array constants for your language.
         <ul>             <li><a href="#.staticTokens">staticTokens</a></li>
             <li><a href="#.dynamicTokens">dynamicTokens</a></li>
             <li><a href="#.possibleDefaultTokens">possibleDefaultTokens</a></li>
             <li><a href="#.tokenHandlers">tokenHandlers</a></li>
         </ul></li>
     <li>Create aliases for the various token and token identifier types
         specific to your language.
         <ul>             <li></li>
             <li></li>
             <li></li>
             <li></li>
         </ul></li>
     <li>Create a struct that mixes in the Lexer template mixin and
         implements the necessary functions.
         <ul>             <li></li>
         </ul></li>
 </ol>
<br><br>
<b>Examples:</b><br>
 <ul> <li>A lexer for D is available <a href="https://github.com/Hackerpilot/Dscanner/blob/master/std/d/lexer.d">here</a>.</li>
 <li>A lexer for Lua is available <a href="https://github.com/Hackerpilot/lexer-demo/blob/master/lualexer.d">here</a>.</li>
 <li>A lexer for JSON is available <a href="https://github.com/Hackerpilot/lexer-demo/blob/master/jsonlexer.d">here</a>.</li>
 </ul>
 <a name="TemplateParameters"></a> 
 <dl> <dt><a name="defaultTokenFunction"></a> <b>defaultTokenFunction</b>
 <dd>A function that serves as the default token lexing function. For most
     languages this will be the identifier lexing function.</dd></dt>
 <dt><a name="tokenSeparatingFunction"></a> <b>tokenSeparatingFunction</b></dt>
 <dd>A function that is able to determine if an identifier/keyword has come
     to an end. This function must return bool and take a single size_t
     argument representing the number of bytes to skip over before looking for
     a separating character.</dd>
 <dt><a name="staticTokens"></a> <b>staticTokens</b></dt>
 <dd>A listing of the tokens whose exact value never changes and which cannot
     possibly be a token handled by the default token lexing function. The
     most common example of this kind of token is an operator such as
     <font color=red>"*"</font>, or <font color=red>"-"</font> in a programming language.</dd>
 <dt><a name="dynamicTokens"></a> <b>dynamicTokens</b></dt>
 <dd>A listing of tokens whose value is variable, such as whitespace,
     identifiers, number literals, and string literals.</dd>
 <dt><a name="possibleDefaultTokens"></a> <b>possibleDefaultTokens</b></dt>
 <dd>A listing of tokens that could posibly be one of the tokens handled by
     the default token handling function. An common example of this is
     a keyword such as <font color=red>"for"</font>, which looks like the beginning of
     the identifier <font color=red>"fortunate"</font>. <b>tokenSeparatingFunction</b> is
     called to determine if the character after the <font color=red>'r'</font> separates
     the identifier, indicating that the token is <font color=red>"for"</font>, or if
     lexing should be turned over to the <b>defaultTokenFunction</b>.</dd>
 <dt><a name="tokenHandlers"></a> <b>tokenHandlers</b></dt>
 <dd>A mapping of prefixes to custom token handling function names. The
     generated lexer will search for the even-index elements of this array,
     and then call the function whose name is the element immedately after the
     even-indexed element. This is used for lexing complex tokens whose prefix
     is fixed.</dd>
 </dl>
<br><br>

 Here are some example constants for a simple calculator lexer:
<pre class="d_code"><font color=green>// There are a near infinite number of valid number literals, so numbers are
</font><font color=green>// dynamic tokens.
</font><font color=blue>enum</font> string[] dynamicTokens = [<font color=red>"numberLiteral"</font>, <font color=red>"whitespace"</font>];

<font color=green>// The operators are always the same, and cannot start a numberLiteral, so
</font><font color=green>// they are staticTokens
</font><font color=blue>enum</font> string[] staticTokens = [<font color=red>"-"</font>, <font color=red>"+"</font>, <font color=red>"*"</font>, <font color=red>"/"</font>];

<font color=green>// In this simple example there are no keywords or other tokens that could
</font><font color=green>// look like dynamic tokens, so this is blank.
</font><font color=blue>enum</font> string[] possibleDefaultTokens = [];

<font color=green>// If any whitespace character or digit is encountered, pass lexing over to
</font><font color=green>// our custom handler functions. These will be demonstrated in an example
</font><font color=green>// later on.
</font><font color=blue>enum</font> string[] tokenHandlers = [
    <font color=red>"0"</font>, <font color=red>"lexNumber"</font>,
    <font color=red>"1"</font>, <font color=red>"lexNumber"</font>,
    <font color=red>"2"</font>, <font color=red>"lexNumber"</font>,
    <font color=red>"3"</font>, <font color=red>"lexNumber"</font>,
    <font color=red>"4"</font>, <font color=red>"lexNumber"</font>,
    <font color=red>"5"</font>, <font color=red>"lexNumber"</font>,
    <font color=red>"6"</font>, <font color=red>"lexNumber"</font>,
    <font color=red>"7"</font>, <font color=red>"lexNumber"</font>,
    <font color=red>"8"</font>, <font color=red>"lexNumber"</font>,
    <font color=red>"9"</font>, <font color=red>"lexNumber"</font>,
    <font color=red>" "</font>, <font color=red>"lexWhitespace"</font>,
    <font color=red>"\n"</font>, <font color=red>"lexWhitespace"</font>,
    <font color=red>"\t"</font>, <font color=red>"lexWhitespace"</font>,
    <font color=red>"\r"</font>, <font color=red>"lexWhitespace"</font>
];
</pre>

<br><br>
<b>License:</b><br>
<a href="http://www.boost.org/LICENSE_1_0.txt Boost">License 1.0</a>
<br><br>
<b>Authors:</b><br>
Brian Schott, with ideas shamelessly stolen from Andrei Alexandrescu
<br><br>
<b>Source:</b><br>
<br><br>

<dl><dt><big><a name="TokenIdType"></a>template <u>TokenIdType</u>(alias staticTokens, alias dynamicTokens, alias possibleDefaultTokens)</big></dt>
<dd>Template for determining the type used for a token type.
<br><br>
Selects the smallest unsigned integral type that is able to hold the value
 staticTokens.length + dynamicTokens.length + possibleDefaultTokens.length.
 For example if there are 20 static tokens, 30 dynamic tokens,
 and 10 possible default tokens, this template will alias itself to ubyte,
 as 20 + 30 + 10 &lt; <font color=blue>ubyte</font>.max.
<br><br>
<b>Examples:</b><br>
<pre class="d_code"><font color=green>// In our calculator example this means that IdType is an alias for ubyte.
</font><font color=blue>alias</font> IdType = <u>TokenIdType</u>!(staticTokens, dynamicTokens, possibleDefaultTokens);
</pre>
<br><br>

</dd>
<dt><big><a name="tokenStringRepresentation"></a>pure nothrow @nogc @property @safe string <u>tokenStringRepresentation</u>(IdType, alias staticTokens, alias dynamicTokens, alias possibleDefaultTokens)(IdType <i>type</i>);
</big></dt>
<dd>Looks up the string representation of the given token <i>type</i>.
<br><br>
This is the opposite of the function of the TokenId template.
<br><br>
<b>Params:</b><br>
<table><tr><td>IdType <i>type</i></td>
<td>the token <i>type</i> identifier</td></tr>
</table><br>
<b>Examples:</b><br>
<pre class="d_code"><font color=blue>alias</font> str = <u>tokenStringRepresentation</u>(IdType, staticTokens, dynamicTokens, possibleDefaultTokens);
<font color=blue>assert</font> (str(tok!<font color=red>"*"</font>) == <font color=red>"*"</font>);
</pre>
<br><br>
<b>See Also:</b><br>
<br><br>

</dd>
<dt><big><a name="TokenId"></a>template <u>TokenId</u>(IdType, alias staticTokens, alias dynamicTokens, alias possibleDefaultTokens, string symbol)</big></dt>
<dd>Generates the token type identifier for the given symbol.
<br><br>
There are two special cases:
 <ul>     <li>If symbol is <font color=red>""</font>, then the token identifier will be 0</li>
     <li>If symbol is <font color=red>"\0"</font>, then the token identifier will be the maximum
         valid token type identifier</li>
 </ul>
 In all cases this template will alias itself to a constant of type IdType.
 This template will fail at compile time if <i>symbol</i> is not one of
 the staticTokens, dynamicTokens, or possibleDefaultTokens.
<br><br>
<b>Examples:</b><br>
<pre class="d_code"><font color=blue>template</font> tok(string symbol)
{
    <font color=blue>alias</font> tok = <u>TokenId</u>!(IdType, staticTokens, dynamicTokens,
        possibleDefaultTokens, symbol);
}
<font color=green>// num and plus are of type ubyte.
</font>IdType plus = tok!<font color=red>"+"</font>;
IdType num = tok!<font color=red>"numberLiteral"</font>;
</pre>
<br><br>

</dd>
<dt><big><a name="TokenStructure"></a>struct <u>TokenStructure</u>(IdType, string extraFields = "");
</big></dt>
<dd>The token that is returned by the lexer.
<br><br>
<b>Params:</b><br>
<table><tr><td>IdType</td>
<td>The D type of the "type" token type field.</td></tr>
<tr><td>extraFields</td>
<td>A string containing D code for any extra fields that should
         be included in the token structure body. This string is passed
         directly to a mixin statement.</td></tr>
</table><br>
<b>Examples:</b><br>
<pre class="d_code"><font color=green>// No extra struct fields are desired in this example, so leave it blank.
</font><font color=blue>alias</font> Token = <u>TokenStructure</u>!(IdType, <font color=red>""</font>);
Token minusToken = Token(tok!<font color=red>"-"</font>);
</pre>
<br><br>

<dl><dt><big><a name="TokenStructure.opEquals"></a>const bool <u>opEquals</u>(IdType <i>type</i>);
</big></dt>
<dd><b>Returs:</b><br>
<b>true</b> if the token has the given <i>type</i>, <b>false</b> otherwise.<br><br>

</dd>
<dt><big><a name="TokenStructure.this"></a>this(IdType <i>type</i>);
</big></dt>
<dd>Constructs a token from a token <i>type</i>.
<br><br>
<b>Params:</b><br>
<table><tr><td>IdType <i>type</i></td>
<td>the token <i>type</i></td></tr>
</table><br>

</dd>
<dt><big><a name="TokenStructure.this.2"></a>this(IdType <i>type</i>, string <i>text</i>, size_t <i>line</i>, size_t <i>column</i>, size_t <i>index</i>);
</big></dt>
<dd>Constructs a token.
<br><br>
<b>Params:</b><br>
<table><tr><td>IdType <i>type</i></td>
<td>the token <i>type</i></td></tr>
<tr><td>string <i>text</i></td>
<td>the <i>text</i> of the token, which may be <b>null</b></td></tr>
<tr><td>size_t <i>line</i></td>
<td>the <i>line</i> number at which this token occurs</td></tr>
<tr><td>size_t <i>column</i></td>
<td>the <i>column</i> number at which this token occurs</td></tr>
<tr><td>size_t <i>index</i></td>
<td>the byte offset from the beginning of the input at which this
         token occurs</td></tr>
</table><br>

</dd>
<dt><big><a name="TokenStructure.text"></a>string <u>text</u>;
</big></dt>
<dd>The text of the token.<br><br>

</dd>
<dt><big><a name="TokenStructure.line"></a>size_t <u>line</u>;
</big></dt>
<dd>The line number at which this token occurs.<br><br>

</dd>
<dt><big><a name="TokenStructure.column"></a>size_t <u>column</u>;
</big></dt>
<dd>The column number at which this token occurs. This is measured in bytes
 and may not be correct when tab characters are involved.<br><br>

</dd>
<dt><big><a name="TokenStructure.index"></a>size_t <u>index</u>;
</big></dt>
<dd>The byte offset from the beginning of the input at which this token
 occurs.<br><br>

</dd>
<dt><big><a name="TokenStructure.type"></a>IdType <u>type</u>;
</big></dt>
<dd>The token <u>type</u>.<br><br>

</dd>
</dl>
</dd>
<dt><big><a name="Lexer"></a>template <u>Lexer</u>(Token, alias defaultTokenFunction, alias tokenSeparatingFunction, alias staticTokens, alias dynamicTokens, alias possibleDefaultTokens, alias tokenHandlers)</big></dt>
<dd>The implementation of the lexer is contained within this mixin template.
<br><br>
To use it, this template should be mixed in to a struct that represents the
 lexer for your language. This struct should implement the following methods:
 <ul>     <li>popFront, which should call this mixin's popFront() and
         additionally perform any token filtering or shuffling you deem
         necessary. For example, you can implement popFront to skip comment or
          tokens.</li>
     <li>A function that serves as the default token lexing function. For
         most languages this will be the identifier lexing function. This
         should then be passed to the  template mixin as the
         <a href="#.defaultTokenFunction defaultTokenFunction"></a> template
         parameter.</li>
     <li>A function that is able to determine if an identifier/keyword has
         come to an end. This function must return <font color=blue>bool</font> and take
         a single <font color=blue>size_t</font> argument representing the number of
         bytes to skip over before looking for a separating character.</li>
     <li>Any functions referred to in the tokenHandlers template paramater.
         These functions must be marked <font color=blue>pure nothrow</font>, take no
         arguments, and return a token</li>
     <li>A constructor that initializes the range field as well as calls
         popFront() exactly once (to initialize the front field).</li>
 </ul>
<br><br>
<b>Params:</b><br>
<table><tr><td>Token</td>
<td></td></tr>
<tr><td>defaultTokenFunction</td>
<td><a href="#.defaultTokenFunction">defaultTokenFunction</a></td></tr>
<tr><td>tokenSeparatingFunction</td>
<td><a href="#.tokenSeparatingFunction">tokenSeparatingFunction</a></td></tr>
<tr><td>staticTokens</td>
<td><a href="#.staticTokens">staticTokens</a></td></tr>
<tr><td>dynamicTokens</td>
<td><a href="#.dynamicTokens">dynamicTokens</a></td></tr>
<tr><td>possibleDefaultTokens</td>
<td><a href="#.possibleDefaultTokens">possibleDefaultTokens</a></td></tr>
<tr><td>tokenHandlers</td>
<td><a href="#.tokenHandlers">tokenHandlers</a></td></tr>
</table><br>
<b>Examples:</b><br>
<pre class="d_code"><font color=blue>struct</font> CalculatorLexer
{
    <font color=blue>mixin</font> <u>Lexer</u>!(IdType, Token, defaultTokenFunction, isSeparating,
        staticTokens, dynamicTokens, possibleDefaultTokens, tokenHandlers);

    <font color=blue>this</font> (<font color=blue>ubyte</font>[] bytes)
    {
        <font color=blue>this</font>.range = LexerRange(bytes);
        popFront();
    }

    <font color=blue>void</font> popFront() <font color=blue>pure</font>
    {
        _popFront();
    }

    Token lexNumber() <font color=blue>pure</font> <font color=blue>nothrow</font> @safe
    {
        <font color=green>// implementation goes here
</font>    }

    Token lexWhitespace() <font color=blue>pure</font> <font color=blue>nothrow</font> @safe
    {
        <font color=green>// implementation goes here
</font>    }

    Token defaultTokenFunction() <font color=blue>pure</font> <font color=blue>nothrow</font> @safe
    {
        <font color=green>// There is no default token in the example calculator language, so
</font>        <font color=green>// this is always an error.
</font>        range.popFront();
        <font color=blue>return</font> Token(tok!<font color=red>""</font>);
    }

    <font color=blue>bool</font> isSeparating(size_t offset) <font color=blue>pure</font> <font color=blue>nothrow</font> @safe
    {
        <font color=green>// For this example language, always return true.
</font>        <font color=blue>return</font> <font color=blue>true</font>;
    }
}
</pre>
<br><br>

<dl><dt><big><a name="Lexer.front"></a>const pure nothrow @property ref @safe const(Token) <u>front</u>()();
</big></dt>
<dd>Implements the range primitive front.<br><br>

</dd>
<dt><big><a name="Lexer._popFront"></a>pure nothrow @safe void <u>_popFront</u>()();
</big></dt>
<dd>Advances the lexer to the next token and stores the new current token in
 the front variable.<br><br>

</dd>
<dt><big><a name="Lexer.empty"></a>const pure nothrow @nogc @property @safe bool <u>empty</u>()();
</big></dt>
<dd>Implements the range primitive empty.<br><br>

</dd>
<dt><big><a name="Lexer.range"></a>LexerRange <u>range</u>;
</big></dt>
<dd>The lexer input.<br><br>

</dd>
<dt><big><a name="Lexer._front"></a>Token <u>_front</u>;
</big></dt>
<dd>The token that is currently at the front of the range.<br><br>

</dd>
</dl>
</dd>
<dt><big><a name="LexerRange"></a>struct <u>LexerRange</u>;
</big></dt>
<dd>Range structure that wraps the lexer's input.<br><br>

<dl><dt><big><a name="LexerRange.this"></a>pure nothrow @nogc @safe this(const(ubyte)[] <i>bytes</i>, size_t <i>index</i> = 0, size_t <i>column</i> = 1, size_t <i>line</i> = 1);
</big></dt>
<dd><b>Params:</b><br>
<table><tr><td>const(ubyte)[] <i>bytes</i></td>
<td>the lexer input</td></tr>
<tr><td>size_t <i>index</i></td>
<td>the initial offset from the beginning of <i><i>bytes</i></i></td></tr>
<tr><td>size_t <i>column</i></td>
<td>the initial column number</td></tr>
<tr><td>size_t <i>line</i></td>
<td>the initial line number</td></tr>
</table><br>

</dd>
<dt><big><a name="LexerRange.mark"></a>const size_t <u>mark</u>()();
</big></dt>
<dd><b>Returns:</b><br>
a <u>mark</u> at the current position that can then be used with slice.<br><br>

</dd>
<dt><big><a name="LexerRange.seek"></a>void <u>seek</u>()(size_t <i>m</i>);
</big></dt>
<dd>Sets the range to the given position.
<br><br>
<b>Params:</b><br>
<table><tr><td>size_t <i>m</i></td>
<td>the position to <u>seek</u> to</td></tr>
</table><br>

</dd>
<dt><big><a name="LexerRange.slice"></a>const const(ubyte)[] <u>slice</u>()(size_t <i>m</i>);
</big></dt>
<dd>Returs a <u>slice</u> of the input byte array between the given mark and the
 current position.
 Params <i>m</i> = the beginning index of the <u>slice</u> to return<br><br>

</dd>
<dt><big><a name="LexerRange.empty"></a>const bool <u>empty</u>()();
</big></dt>
<dd>Implements the range primitive empty.<br><br>

</dd>
<dt><big><a name="LexerRange.front"></a>const ubyte <u>front</u>()();
</big></dt>
<dd>Implements the range primitive front.<br><br>

</dd>
<dt><big><a name="LexerRange.peek"></a>const pure nothrow @nogc @safe const(ubyte)[] <u>peek</u>(size_t <i>p</i>);
</big></dt>
<dd><b>Returns:</b><br>
the current item as well as the items <i><i>p</i></i> items ahead.<br><br>

</dd>
<dt><big><a name="LexerRange.startsWith"></a>const pure nothrow @nogc @safe bool <u>startsWith</u>(const(ubyte[]) <i>needle</i>);
</big></dt>
<dd><b>Returns:</b><br>
<b>true</b> if the range starts with the given byte sequence<br><br>

</dd>
<dt><big><a name="LexerRange.peekAt"></a>const ubyte <u>peekAt</u>()(size_t <i>offset</i>);
</big></dt>
<dd><br><br>
</dd>
<dt><big><a name="LexerRange.canPeek"></a>const bool <u>canPeek</u>()(size_t <i>p</i>);
</big></dt>
<dd><b>Returns:</b><br>
<b>true</b> if it is possible to peek <i><i>p</i></i> bytes ahead.<br><br>

</dd>
<dt><big><a name="LexerRange.popFront"></a>void <u>popFront</u>()();
</big></dt>
<dd>Implements the range primitive popFront.<br><br>

</dd>
<dt><big><a name="LexerRange.popFrontN"></a>void <u>popFrontN</u>()(size_t <i>n</i>);
</big></dt>
<dd>Implements the algorithm popFrontN more efficiently. This function does
 not detect or handle newlines.<br><br>

</dd>
<dt><big><a name="LexerRange.incrementLine"></a>void <u>incrementLine</u>()(size_t <i>i</i> = 1);
</big></dt>
<dd>Increments the range's line number and resets the column counter.<br><br>

</dd>
<dt><big><a name="LexerRange.bytes"></a>const(ubyte)[] <u>bytes</u>;
</big></dt>
<dd>The input bytes.<br><br>

</dd>
<dt><big><a name="LexerRange.index"></a>size_t <u>index</u>;
</big></dt>
<dd>The range's current position.<br><br>

</dd>
<dt><big><a name="LexerRange.column"></a>size_t <u>column</u>;
</big></dt>
<dd>The current column number.<br><br>

</dd>
<dt><big><a name="LexerRange.line"></a>size_t <u>line</u>;
</big></dt>
<dd>The current line number.<br><br>

</dd>
</dl>
</dd>
</dl>

        <hr><small>Page generated by <a href="http://dlang.org/ddoc.html">Ddoc</a>. Brian Schott 2013
</small>
        </body></html>
